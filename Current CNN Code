import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras import layers
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
plt.style.use('fivethirtyeight')
import csv
import math
import tkinter
from csv import reader
import pandas as pd
import matplotlib.colors
import matplotlib.cm as cm
from sklearn.model_selection import train_test_split
import random
import datetime
import random

color_max_pT=1000000.
color_min_pT=30000.

import uproot
filename = r'new_TTHH.root'
signal=uproot.open(filename)
tree=signal["OutputTree"]
branches = tree.arrays()
numevents=len(branches["met"])

eta_values_all = []
phi_values_all = []
pT_values_all = []
b_values_all = []

eta_bin_size = 0.2
phi_bin_size = math.pi/20
eta_min, eta_max = np.min(-5), np.max(5)
phi_min, phi_max = np.min(-math.pi), np.max(math.pi)
num_eta_bins = int(2*eta_max/eta_bin_size)  #50
num_phi_bins = int(2*phi_max/phi_bin_size)  #40
num_rand_pixels = 5
  
for j in range(1, 11):
    pT_values_all.append(branches['jet' + str(j) + 'pT'])
    eta_values_all.append(branches['jet' + str(j) + 'eta'])
    phi_values_all.append(branches['jet' + str(j) + 'phi'])  
    b_values_all.append(branches['jet' + str(j) + 'btag'])

    
def makePlotFromEvent(eventnumber):
    pT_values = [pT_values_all[k][eventnumber] for k in range(len(pT_values_all))]
    eta_values= [eta_values_all[k][eventnumber] for k in range(len(eta_values_all))]
    phi_values= [phi_values_all[k][eventnumber] for k in range(len(phi_values_all))]

    points = None
    points = list(zip(eta_values, phi_values, pT_values))

    eta_array = np.array(eta_values)
    phi_array = np.array(phi_values)
    pT_array = np.array(pT_values)
    
    #njets = 0

    # CODE TO CREATE THE 2D HISTOGRAM

    eta_index = np.floor(eta_array / eta_bin_size).astype(int)
    phi_index = np.floor(phi_array / phi_bin_size).astype(int)

    array = np.zeros(shape = (num_eta_bins,num_phi_bins))
    np.set_printoptions(threshold=np.inf)
    larray=[]
    for ie in range(num_eta_bins):
        larray.append([])
        for ip in range(num_phi_bins):
            larray[ie].append([1.,1.,1.])                

    for i in range(0, len(pT_values)):
        #if filename == r'new_TTHH.root':
        if pT_values[i] > 0:
            ptcolor_rgb=cm.Blues(min(pT_values[i]/color_max_pT,1.))[:3]
            array[eta_index[i] + int(num_eta_bins / 2), phi_index[i] + int(num_phi_bins / 2)] = pT_values[i]             
            larray[eta_index[i] + int(num_eta_bins / 2)][phi_index[i] + int(num_phi_bins / 2)] = ptcolor_rgb
            #njets += 1
#         else:
#              if pT_values[i] > 0:
#                 ptcolor_rgb=cm.Blues(min(pT_values[i]/color_max_pT,1.))[:3]
#                 array[eta_index[i] + int(num_eta_bins / 2), phi_index[i] + int(num_phi_bins / 2)] = pT_values[i]             
#                 larray[eta_index[i] + int(num_eta_bins / 2)][phi_index[i] + int(num_phi_bins / 2)] = [0, 0, 0]
                
    if filename == r'new_TTHH.root':
        for i in range(num_eta_bins):
            for j in range(num_phi_bins):
                chance = random.random()
                if chance < 0.001:                     
                    larray[i][j] = [0, 0, 0]
            

    x,y = array.nonzero() #get the notzero indices
    if False:
        plt.scatter(x,y,c=array[x,y],s=50,cmap='winter',marker='s') #adjust the size to your needs
        plt.xlim(0, 50)
        plt.ylim(0, 40)
        plt.colorbar()
        plt.show()

    return larray


# loop over events
larray=None
for i in range(numevents):
    
    # just a way to only generate one event for now
    if i>0: break

    #print(pT_values)    # all pT arrays for all events
    #print(pT_values[0]) # pT(j1) for all events
    #print(pT_values[0][i]) # pT(j1) for i'th event
    #print([pT_values[k][i] for k in range(len(pT_values))]) # [pT(j1), pT(j2), ..., pT(j10)] for i'th event
    larray = makePlotFromEvent(i)
    
    # make x a dictionary and update the values

x = np.zeros(shape=(50000, 50, 40, 3))           # create as empty numpy array with 1 mil elements
flipped_events = []
shifted_events = []
signal_njets_list = []

iter = 25000
start_time = datetime.datetime.now()
for i in range(0, iter):
    begin_time = datetime.datetime.now()
    larray = makePlotFromEvent(i)
    mc_event = np.array(larray)
    x[i] = mc_event
    #signal_njets_list.append(njets)
    event_time=(datetime.datetime.now()-begin_time).total_seconds()
    
print(datetime.datetime.now() - start_time)
y=np.array([[1] for i in range(iter)])

filename = r'new_TTBB.root'
background=uproot.open(filename)
tree=background["OutputTree"]
branches = tree.arrays()

eta_values_all = []
phi_values_all = []
pT_values_all = []
b_values_all = []

for j in range(1, 11):
    pT_values_all.append(branches['jet' + str(j) + 'pT'])
    eta_values_all.append(branches['jet' + str(j) + 'eta'])
    phi_values_all.append(branches['jet' + str(j) + 'phi'])  
    b_values_all.append(branches['jet' + str(j) + 'btag'])
    
background_njets_list = []

start_time = datetime.datetime.now()
for i in range(0, iter):
    begin_time = datetime.datetime.now()
    larray = makePlotFromEvent(i)
    mc_event2 = larray
    x[i + iter] = mc_event2
    #background_njets_list.append(njets)
    event_time=(datetime.datetime.now()-begin_time).total_seconds()

print(datetime.datetime.now() - start_time)
rows, cols = (iter, 1)
y2=np.array([[0] for i in range(iter)]) # append, not replace
y = np.concatenate((y, y2))

#Create the models architecture

model = Sequential()

#Add the first layer
model.add( Conv2D(128, (3,3), activation='relu', input_shape=(50,40,3)) )

#Add a pooling layer
model.add(MaxPooling2D(pool_size = (2,2)))

#Add another convolutional layer
model.add( Conv2D(128, (3,3), activation='relu') )

#Add another pooling layer
model.add(MaxPooling2D(pool_size = (2,2)))

#Add another convolutional layer
model.add( Conv2D(128, (3,3), activation='relu') )

#Add another pooling layer
model.add(MaxPooling2D(pool_size = (2,2)))

#Add a flattening layer
model.add(Flatten())

#Add a layer with 1000 neurons
model.add(Dense(1000, activation='relu'))

#Add a dropout layer
model.add(Dropout(0.5))

#Add a layer with 500 neurons
model.add(Dense(500, activation='relu'))

#Add a dropout layer
model.add(Dropout(0.5))

#Add a layer with 250 neurons
#model.add(Dense(250, activation='relu'))

#Add an output layer with 1 neuron
model.add(Dense(1, activation='sigmoid'))

#Compile the model

opt = tf.keras.optimizers.Adam()

model.compile(loss = 'binary_crossentropy',
             optimizer = opt,
             metrics = ['accuracy'])
             
# Use train_test_split to randomize the events into training sets and test sets

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=42)

# Train the model with our data

model.summary()

history = model.fit(x_train, y_train,
                batch_size = 100,
                epochs = 5,
                validation_split = 0.2)

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
